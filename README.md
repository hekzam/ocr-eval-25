# ğŸ§  Projet BE_25 â€“ HEKZAM OCR

HEKZAM est une suite dâ€™outils dÃ©veloppÃ©e dans le but dâ€™automatiser le traitement dâ€™images scannÃ©es de copies dâ€™Ã©tudiants, en ciblant particuliÃ¨rement la dÃ©tection et la reconnaissance de chiffres manuscrits (par exemple : numÃ©ros dâ€™Ã©tudiant). Le projet repose sur une chaÃ®ne de traitement intÃ©grant des techniques avancÃ©es de prÃ©traitement dâ€™image, de tri, dâ€™Ã©tiquetage, ainsi que de reconnaissance automatique, sâ€™appuyant sur des moteurs spÃ©cialisÃ©s implÃ©mentant des algorithmes dâ€™extraction de caractÃ©ristiques et de classification.

Ce projet a Ã©galement pour vocation de comparer les performances des diffÃ©rents algorithmes testÃ©s dans la phase de reconnaissance, tant en termes de prÃ©cision que de coÃ»t computationnel. Cette dÃ©marche comparative vise Ã  identifier le compromis entre la prÃ©cision des rÃ©sultats et le cout des ressources mobilisÃ©es.

---

## ğŸ“œ License

- Code: Apache-2.0
- Everything else, in particular documentation and measurements: CC-BY-SA-4.0

---

## ğŸ‘¥ Contributeurs

- Nourhane MALLEK
- Yennayer BENAMEUR
- Omar KARAM
- Paulin LAURENT

---

## ğŸ“ Structure du projet
```bash
ocr_eval_25/
â”œâ”€â”€ resources/
â”‚   â”œâ”€â”€ parsed-200dpi/       â†’ DonnÃ©es scannÃ©es brutes
â”‚   â”œâ”€â”€ mnist/               â†’ Extraits du dataset MNIST original
â”‚   â”œâ”€â”€ custom/              â†’ Images prÃ©traitÃ©es prÃªtes pour l'entraÃ®nement
â”‚   â”œâ”€â”€ data_utilisees       â†’ DonnÃ©es prÃªte a Ãªtre utilisÃ©e par les modÃ¨les 
â”‚   â”œâ”€â”€ paths_*.txt          â†’ Fichiers contenant les chemins vers les images
â”‚   â”œâ”€â”€ mnist_label.txt      â†’ Labels associÃ©s aux images mnist
â”‚   â””â”€â”€ custom_label.txt     â†’ Labels associÃ©s aux images custom
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ models/              â†’ Stockage des models entrainÃ©s
â”‚   â”œâ”€â”€ results_algo/        â†’ Stockage des donnÃ©es produites par les models
â”‚   â”œâ”€â”€ temps_entrainement/  â†’ Stockage du temps d'entrainement des models et du temps d'extraction de features
â”‚   â””â”€â”€ visuels/             â†’ Stockage des rendus visuels des rÃ©sultats et comparaisons des models
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ prep/
â”‚   â”‚   â”œâ”€â”€ generate_mnist_paths.py   â†’ GÃ©nÃ©re les paths des images mnist
â”‚   â”‚   â”œâ”€â”€ generate_custom_paths.py  â†’ GÃ©nÃ©re les paths des images custom
â”‚   â”‚   â”œâ”€â”€ generate_custom_label.py  â†’ GÃ©nÃ©re les labels des images custom
â”‚   â”‚   â”œâ”€â”€ generate_parsed_paths.py  â†’ GÃ©nÃ©re les paths des images brutes
â”‚   â”‚   â””â”€â”€ preprocessing.py          â†’ PrÃ©traitement des images
â”‚   â”œâ”€â”€ algorithm/
â”‚   â”‚   â”œâ”€â”€ knn_search.py             â†’ Recherche des meilleurs paramÃ¨tres de knn
â”‚   â”‚   â”œâ”€â”€ knn.py                    â†’ Model de reconnaissance basÃ© sur knn
â”‚   â”‚   â”œâ”€â”€ linear_svm.py             â†’ Model de reconnaissance basÃ© sur linear svm, non inclus dans le cli car non pertinant
â”‚   â”‚   â”œâ”€â”€ logistic_regression.py    â†’ Model de reconnaissance basÃ© sur logistic regression
â”‚   â”‚   â”œâ”€â”€ random_forest.py          â†’ Model de reconnaissance basÃ© sur random forest
â”‚   â”‚   â””â”€â”€ svm.py                    â†’ Model de reconnaissance basÃ© sur svm
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ extraction_features.py    â†’ Permet de rÃ©cupÃ©rer les features depuis les images
â”‚   â”‚   â”œâ”€â”€ main_tools.py             â†’ Permet d'exÃ©cuter le reste du programme sans saturer hekzam.ocr
â”‚   â”‚   â”œâ”€â”€ preparation_donnees.py    â†’ Transforme les images prÃ©traitÃ©es en donnÃ©es utilisable par les models
â”‚   â”‚   â””â”€â”€ sauvegarde_csv.py         â†’ Sauvegarde les rÃ©sultats des models en csv 
â”‚   â””â”€â”€ hekzam_ocr.py        â†’ Agis en tant que main, contient le cli
â””â”€â”€ README.txt              â†’ Ce fichier
```
---

## âš™ï¸ FonctionnalitÃ©s principales

Le projet heckzam_ocr propose une suite complÃ¨te d'outils pour la gestion de pipelines d'OCR basÃ©s sur des algorithmes de machine learning classiques.

Reconstruction des donnÃ©es

    Fusionne des jeux de donnÃ©es (ex : MNIST + dataset personnalisÃ©)
    
    Extrait des caractÃ©ristiques (flatten, zoning, 4lrp)
    
    Divise automatiquement en train/test selon un ratio dÃ©fini

EntraÃ®nement de modÃ¨les

    Supporte plusieurs algorithmes :
    
        KNN (K-Nearest Neighbors)
        
        SVM (Support Vector Machine)
        
        Random Forest
        
        Logistic Regression
        
        Linear SVM
        
    PossibilitÃ© de rÃ©gler les sous-ensembles d'entraÃ®nement et hyperparamÃ¨tres

ExÃ©cution et Ã©valuation

    Charge les modÃ¨les entraÃ®nÃ©s et prÃ©dit sur les donnÃ©es de test
    
    Calcule automatiquement :
    
        Accuracy
        
        Precision
        
        Recall
        
        F1-Score
        
        Balanced Accuracy
    
    GÃ©nÃ¨re une matrice de confusion par modÃ¨le
    
    ChronomÃ¨tre les temps d'entraÃ®nement et d'infÃ©rence

Export et rapports
    
    Sauvegarde des rÃ©sultats au format :
    
        .json (matrices, rÃ©sultats bruts)
        
        .csv (rÃ©sumÃ© des performances)
    
    Structure de dossiers personnalisable
    
    Rapports compatibles avec des outils dâ€™analyse externes

---

## ğŸš€ ExÃ©cution (explication cli)
Commandes gÃ©nÃ©rales
| Option           | Description                                                                                                                                      |
| ---------------- | ------------------------------------------------------------------------------------------------------------------------------------------------ |
| `--rebuild_data` | Reconstruit les donnÃ©es Ã  partir des fichiers label (MNIST et custom). Active les options `--r_features`, `--r_training_ratio`, `--r_data_size`. |
| `--train`        | Liste des modÃ¨les Ã  entraÃ®ner (sÃ©parÃ©s par virgule). Valeurs autorisÃ©es : `knn`, `svm`, `rf`, `lr`, `linear_svm`.                                |
| `--model`        | Liste des modÃ¨les Ã  exÃ©cuter sur les donnÃ©es de test. Identiques Ã  ceux disponibles avec `--train`.                                              |

Options liÃ©es Ã  --rebuild_data
| Option               | Description                                                                                                           |
| -------------------- | --------------------------------------------------------------------------------------------------------------------- |
| `--r_features`       | MÃ©thodes dâ€™extraction de caractÃ©ristiques. Valeurs : `flatten`, `zoning`, `4lrp`. Combinaison possible avec virgules. |
| `--r_training_ratio` | Ratio du dataset Ã  utiliser pour l'entraÃ®nement. Float entre `0.1` et `0.99`. Par dÃ©faut : `0.8`.                     |
| `--r_data_size`      | Nombre total dâ€™images Ã  utiliser (maximum = taille totale des labels). Par dÃ©faut : toutes.                           |

Options liÃ©es Ã  --train
| Option                       | Description                                                                  |
| ---------------------------- | ---------------------------------------------------------------------------- |
| `--t_custom_output`          | Dossier de sauvegarde des modÃ¨les entraÃ®nÃ©s. Par dÃ©faut : `results/models/`. |
| `--knn_subset`               | Nombre d'exemples utilisÃ©s pour entraÃ®ner le KNN. `-1` pour tout utiliser.   |
| `--svm_subset`               | Idem pour SVM.                                                               |
| `--svm_regulation_parameter` | HyperparamÃ¨tre de rÃ©gularisation pour le SVM.                                |
| `--rf_subset`                | Idem pour Random Forest.                                                     |
| `--lr_subset`                | Idem pour Logistic Regression.                                               |

Options liÃ©es Ã  --model
| Option              | Description                                                                                          |
| ------------------- | ---------------------------------------------------------------------------------------------------- |
| `--m_custom_input`  | Dossier contenant les modÃ¨les entraÃ®nÃ©s (Ã  exÃ©cuter). Par dÃ©faut : `results/confusion_matrices/`.    |
| `--m_custom_output` | Dossier de sortie pour les rÃ©sultats et matrices de confusion. Par dÃ©faut : `results/results_algo/`. |

Exemple execution complete par defaut:
`--rebuild_data --train knn,svm,rf,lr --test knn,svm,lr,rf --m_confusion_matrix --m_visuals_construction`

---

## ğŸ§© PrÃ©requis Python

- Python 3.8 ou plus
- DÃ©pendances listÃ©es dans le fichier `requirements.txt`

Installation recommandÃ©e :
```bash
pip install -r requirements.txt
```
