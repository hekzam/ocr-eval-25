=======================================================
ğŸ“„ Documentation - evaluate_on_mnist.py
=======================================================

ğŸ¯ Objectif :
--------------
Ce script Ã©value les performances de 4 modÃ¨les de classification sur les donnÃ©es MNIST
(en version image + labels fournis localement).

ğŸ“¥ DonnÃ©es utilisÃ©es :
-----------------------
- Chemins des images : resources/paths_mnist.txt
- Labels associÃ©s : resources/mnist_label.txt
- Format des images : 28x28 px (binarisÃ©es et centrÃ©es), vectorisÃ©es en 784 dimensions

ğŸ“¦ ModÃ¨les Ã©valuÃ©s :
---------------------
- SVM (Support Vector Machine)
- RÃ©gression Logistique
- Random Forest
- k-Nearest Neighbors

Les modÃ¨les doivent Ãªtre dÃ©jÃ  entraÃ®nÃ©s et stockÃ©s dans le dossier `models/` au format `.pkl`.

ğŸ”„ Ã‰tapes principales :
------------------------
1. Lecture des images et labels depuis les fichiers.
2. Chargement de chaque modÃ¨le.
3. PrÃ©dictions sur les images MNIST.
4. Affichage de lâ€™accuracy et dâ€™un rapport dÃ©taillÃ© (precision, recall, f1-score).
5. (Optionnel) Matrice de confusion disponible en commentaire.

ğŸ§ª Librairies utilisÃ©es :
--------------------------
- numpy
- opencv-python
- scikit-learn
- joblib

ğŸ“ RÃ©sultats :
---------------
- Mesure la qualitÃ© de chaque modÃ¨le sur les donnÃ©es MNIST locales
- Utile pour vÃ©rifier que les modÃ¨les ont bien appris pendant lâ€™entraÃ®nement