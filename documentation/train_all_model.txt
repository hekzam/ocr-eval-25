======================================
📄 Documentation - train_all_models.py
======================================

🎯 Objectif :
--------------
Ce script entraîne 4 modèles de classification sur les données MNIST (chiffres manuscrits)
et sauvegarde chaque modèle dans un fichier .pkl pour un usage ultérieur.

📦 Modèles entraînés :
-----------------------
- SVM (Support Vector Machine)
- Régression Logistique (LogisticRegression)
- Random Forest
- k-Nearest Neighbors (kNN)

📁 Données utilisées :
-----------------------
- Images listées dans : resources/paths_mnist.txt
- Labels associés dans : resources/mnist_label.txt
- Chaque image est une image 28x28 pixels en niveaux de gris, convertie en vecteur de 784 valeurs.

🔄 Étapes principales :
------------------------
1. Chargement des chemins d’images et des labels.
2. Lecture et vectorisation des images avec OpenCV.
3. Entraînement de chaque modèle avec scikit-learn.
4. Sauvegarde des modèles au format .pkl dans le dossier `models/`.

🧪 Librairies utilisées :
--------------------------
- numpy
- opencv-python (cv2)
- scikit-learn
- joblib

📍 Fichiers générés :
----------------------
- models/svm_model.pkl
- models/logreg_model.pkl
- models/rf_model.pkl
- models/knn_model.pkl

----------------------
🧐 Pourquoi utiliser .pkl pour les modèles ?

Quand tu entraînes un modèle avec scikit-learn, celui-ci devient un objet Python complexe contenant :
-Des formules mathématiques
-Des poids, des arbres, des vecteurs, etc.
-Des hyperparamètres
-La structure du modèle
Tout ça ne peut pas être stocké en .txt ou .json simplement.
➡️ joblib.dump() utilise Pickle sous le capot, mais de manière plus rapide et optimisée pour les gros objets (comme les modèles).